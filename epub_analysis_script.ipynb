{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d614e9",
   "metadata": {
    "cell_marker": "\"\"\""
   },
   "source": [
    "EPUB Structure Exploration - Verify Paragraph Boundaries Exist\n",
    "\n",
    "This script examines the raw EPUB structure to verify:\n",
    "1. Do paragraph boundaries exist in the source EPUB?\n",
    "2. What format are they in (HTML <p> tags, newlines, etc.)?\n",
    "3. How should we extract them properly?\n",
    "\n",
    "Run this BEFORE building the full extraction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "583a42a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exploratory EPUB Analysis\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import ebooklib\n",
    "from ebooklib import epub\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "print(\"Exploratory EPUB Analysis\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "77840224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examining: Clear_Light_of_Bliss.epub\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "EPUB_PATH = r\"C:\\Users\\DELL\\Documents\\gesha_la_rag\\epub_directory\\epub_directory\\Clear_Light_of_Bliss.epub\"\n",
    "\n",
    "print(f\"\\nExamining: Clear_Light_of_Bliss.epub\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be75a557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ EPUB loaded successfully\n",
      "Title: Clear Light of Bliss\n"
     ]
    }
   ],
   "source": [
    "# Load EPUB\n",
    "book = epub.read_epub(EPUB_PATH)\n",
    "\n",
    "print(\"\\n✓ EPUB loaded successfully\")\n",
    "\n",
    "# Get metadata\n",
    "try:\n",
    "    title = book.get_metadata('DC', 'title')\n",
    "    print(f\"Title: {title[0][0] if title else 'Unknown'}\")\n",
    "except:\n",
    "    print(\"Title: Unable to extract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f192ea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total document sections: 89\n",
      "\n",
      "First 5 sections:\n",
      "  1. cover.xhtml\n",
      "  2. Clear_Light_of_Bliss_Text_2019-08.xhtml\n",
      "  3. Clear_Light_of_Bliss_Text_2019-08-1.xhtml\n",
      "  4. Clear_Light_of_Bliss_Text_2019-08-2.xhtml\n",
      "  5. Clear_Light_of_Bliss_Text_2019-08-3.xhtml\n"
     ]
    }
   ],
   "source": [
    "# Get all document items\n",
    "items = [item for item in book.get_items() if item.get_type() == ebooklib.ITEM_DOCUMENT]\n",
    "\n",
    "print(f\"\\nTotal document sections: {len(items)}\")\n",
    "print(\"\\nFirst 5 sections:\")\n",
    "for i, item in enumerate(items[:5]):\n",
    "    print(f\"  {i+1}. {item.get_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c95793ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DETAILED EXAMINATION OF FIRST CONTENT SECTION\n",
      "======================================================================\n",
      "\n",
      "Examining: Clear_Light_of_Bliss_Text_2019-08-9.xhtml\n",
      "\n",
      "Raw HTML length: 4117 characters\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "RAW HTML SAMPLE (first 1000 characters):\n",
      "----------------------------------------------------------------------\n",
      "<?xml version='1.0' encoding='utf-8'?>\n",
      "<!DOCTYPE html>\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:epub=\"http://www.idpf.org/2007/ops\" epub:prefix=\"z3998: http://www.daisy.org/z3998/2012/vocab/structure/#\" lang=\"en\" xml:lang=\"en\">\n",
      "  <head/>\n",
      "  <body><div>\n",
      "\t\t\t<p id=\"_idParaDest-6\" class=\"Chapter-title-TOC-Level-1\"><a id=\"_idTextAnchor005\"/>Preface</p>\n",
      "\t\t\t<p class=\"Text-1st-para\">I have written this book primarily for the benefit of Western Dharma practitioners with the hope that indirectly it will prove beneficial for all living beings.</p>\n",
      "\t\t\t<p class=\"Text-2nd-para\">As for how it was composed, I have based it on the slight experience I have gained through the kindness of my holy Spiritual Guide from whom I received instructions on the generation stage and completion stage of Secret Mantra. In addition, I have drawn material from Je Tsongkhapa’s <a id=\"_idIndexMarker002\"/><span class=\"Italic\">Lamp Thoroughly Illuminating the Five Stages</span>, which contains the quintessence of <a\n"
     ]
    }
   ],
   "source": [
    "# Examine the FIRST content section in detail\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED EXAMINATION OF FIRST CONTENT SECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Skip title pages, get to actual content (usually around item 8-12)\n",
    "test_item = items[10] if len(items) > 10 else items[0]\n",
    "\n",
    "print(f\"\\nExamining: {test_item.get_name()}\")\n",
    "\n",
    "# Get raw HTML\n",
    "raw_html = test_item.get_content().decode('utf-8', errors='replace')\n",
    "\n",
    "print(f\"\\nRaw HTML length: {len(raw_html)} characters\")\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"RAW HTML SAMPLE (first 1000 characters):\")\n",
    "print(\"-\" * 70)\n",
    "print(raw_html[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75d59781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PARSED HTML STRUCTURE\n",
      "======================================================================\n",
      "\n",
      "Number of <p> tags found: 8\n",
      "\n",
      "First 3 paragraphs:\n",
      "\n",
      "[Paragraph 1]\n",
      "Length: 7 characters\n",
      "Text: Preface...\n",
      "Has <p> tag: YES\n",
      "\n",
      "[Paragraph 2]\n",
      "Length: 160 characters\n",
      "Text: I have written this book primarily for the benefit of Western Dharma practitioners with the hope that indirectly it will prove beneficial for all living beings....\n",
      "Has <p> tag: YES\n",
      "\n",
      "[Paragraph 3]\n",
      "Length: 894 characters\n",
      "Text: As for how it was composed, I have based it on the slight experience I have gained through the kindness of my holy Spiritual Guide from whom I received instructions on the generation stage and complet...\n",
      "Has <p> tag: YES\n"
     ]
    }
   ],
   "source": [
    "# Parse with BeautifulSoup\n",
    "soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PARSED HTML STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for paragraph tags\n",
    "paragraphs = soup.find_all('p')\n",
    "print(f\"\\nNumber of <p> tags found: {len(paragraphs)}\")\n",
    "\n",
    "if paragraphs:\n",
    "    print(\"\\nFirst 3 paragraphs:\")\n",
    "    for i, p in enumerate(paragraphs[:3], 1):\n",
    "        text = p.get_text()\n",
    "        print(f\"\\n[Paragraph {i}]\")\n",
    "        print(f\"Length: {len(text)} characters\")\n",
    "        print(f\"Text: {text[:200]}...\")\n",
    "        print(f\"Has <p> tag: YES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "169dea5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TEXT EXTRACTION TEST - PRESERVING WHITESPACE\n",
      "======================================================================\n",
      "\n",
      "Extracted text length: 2824 characters\n",
      "\n",
      "Whitespace analysis:\n",
      "  Single newlines (\\n): 16\n",
      "  Double newlines (\\n\\n): 4\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "TEXT SAMPLE (with whitespace preserved):\n",
      "----------------------------------------------------------------------\n",
      "'\\n\\n\\n\\n\\nPreface\\nI have written this book primarily for the benefit of Western Dharma practitioners with the hope that indirectly it will prove beneficial for all living beings.\\nAs for how it was composed, I have based it on the slight experience I have gained through the kindness of my holy Spiritual Guide from whom I received instructions on the generation stage and completion stage of Secret Mantra. In addition, I have drawn material from Je Tsongkhapa’s Lamp Thoroughly Illuminating the Five Stages, which contains the quintessence of Je Tsongkhapa’s Tantric teachings, and also from Je Tsongkhapa’s commentary to the Six Yogas of Naropa. I have also consulted the first Panchen Lama’s root text on the Mahamudra, The Main Path of the Conquerors, and his autocommentary, Lamp of Re-illumination, as well as the Mahamudra texts of Kachen Yeshe Gyaltsen and Keutsang, and many other authentic works on Secret Mantra. Because I have incorporated the teachings of such great Masters, there is some reason to hope that this present book will be of considerable benefit.\\nTo attain pure realizations of Mahamudra, it is not sufficient merely to read these instructions. First we must train in the stages of the path common to both Sutra and Tantra by relying upon texts such as Joyful Path of Good Fortune, and practise the various preliminaries so as to remove obstacles and accumulate merit. When we have some experience of renunciation, bodhichitta, and wisdom realizing emptiness, we should receive '\n"
     ]
    }
   ],
   "source": [
    "# Extract text WITHOUT collapsing whitespace (the key test)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TEXT EXTRACTION TEST - PRESERVING WHITESPACE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Method 1: Get text while preserving structure\n",
    "text_with_structure = soup.get_text()\n",
    "\n",
    "print(f\"\\nExtracted text length: {len(text_with_structure)} characters\")\n",
    "\n",
    "# Check for newlines\n",
    "newline_count = text_with_structure.count('\\n')\n",
    "double_newline_count = text_with_structure.count('\\n\\n')\n",
    "\n",
    "print(f\"\\nWhitespace analysis:\")\n",
    "print(f\"  Single newlines (\\\\n): {newline_count}\")\n",
    "print(f\"  Double newlines (\\\\n\\\\n): {double_newline_count}\")\n",
    "\n",
    "# Show first 1500 characters with newlines visible\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"TEXT SAMPLE (with whitespace preserved):\")\n",
    "print(\"-\" * 70)\n",
    "print(repr(text_with_structure[:1500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "da4f732e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARISON: COLLAPSED vs PRESERVED WHITESPACE\n",
      "======================================================================\n",
      "\n",
      "Original (preserved):  2824 chars, 4 paragraph breaks\n",
      "Collapsed (old way):   2815 chars, 0 paragraph breaks\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Collapsed version sample:\n",
      "----------------------------------------------------------------------\n",
      "Preface I have written this book primarily for the benefit of Western Dharma practitioners with the hope that indirectly it will prove beneficial for all living beings. As for how it was composed, I have based it on the slight experience I have gained through the kindness of my holy Spiritual Guide from whom I received instructions on the generation stage and completion stage of Secret Mantra. In addition, I have drawn material from Je Tsongkhapa’s Lamp Thoroughly Illuminating the Five Stages, w\n"
     ]
    }
   ],
   "source": [
    "# Compare: What happens if we collapse whitespace (the old way)?\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPARISON: COLLAPSED vs PRESERVED WHITESPACE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Old method (destroys paragraphs)\n",
    "text_collapsed = re.sub(r'\\s+', ' ', text_with_structure).strip()\n",
    "\n",
    "print(f\"\\nOriginal (preserved):  {len(text_with_structure)} chars, {double_newline_count} paragraph breaks\")\n",
    "print(f\"Collapsed (old way):   {len(text_collapsed)} chars, {text_collapsed.count(chr(10)+chr(10))} paragraph breaks\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Collapsed version sample:\")\n",
    "print(\"-\" * 70)\n",
    "print(text_collapsed[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac06961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PROPOSED EXTRACTION METHOD\n",
      "======================================================================\n",
      "\n",
      "Method used: HTML_P_TAGS\n",
      "Extracted length: 2822 characters\n",
      "Paragraph breaks (\\n\\n): 7\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Sample of properly extracted text:\n",
      "----------------------------------------------------------------------\n",
      "Preface\n",
      "\n",
      "I have written this book primarily for the benefit of Western Dharma practitioners with the hope that indirectly it will prove beneficial for all living beings.\n",
      "\n",
      "As for how it was composed, I have based it on the slight experience I have gained through the kindness of my holy Spiritual Guide from whom I received instructions on the generation stage and completion stage of Secret Mantra. In addition, I have drawn material from Je Tsongkhapa’s Lamp Thoroughly Illuminating the Five Stages, which contains the quintessence of Je Tsongkhapa’s Tantric teachings, and also from Je Tsongkhapa’s commentary to the Six Yogas of Naropa. I have also consulted the first Panchen Lama’s root text on the Mahamudra, The Main Path of the Conquerors, and his autocommentary, Lamp of Re-illumination, as \n"
     ]
    }
   ],
   "source": [
    "# Test extraction method that preserves paragraphs\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PROPOSED EXTRACTION METHOD\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def extract_paragraphs_properly(soup):\n",
    "    \"\"\"\n",
    "    Extract text preserving paragraph structure.\n",
    "    \n",
    "    Strategy:\n",
    "    1. Find all <p> tags (if they exist)\n",
    "    2. Extract text from each <p>\n",
    "    3. Join with double newlines\n",
    "    4. Clean up excessive whitespace WITHIN paragraphs only\n",
    "    \"\"\"\n",
    "    paragraphs = soup.find_all('p')\n",
    "    \n",
    "    if paragraphs:\n",
    "        # Method A: HTML has <p> tags\n",
    "        para_texts = []\n",
    "        for p in paragraphs:\n",
    "            text = p.get_text()\n",
    "            # Clean whitespace WITHIN paragraph, but preserve paragraph boundaries\n",
    "            text = re.sub(r'\\s+', ' ', text).strip()\n",
    "            if text:\n",
    "                para_texts.append(text)\n",
    "        \n",
    "        # Join with double newlines\n",
    "        result = '\\n\\n'.join(para_texts)\n",
    "        return result, \"HTML_P_TAGS\"\n",
    "    else:\n",
    "        # Method B: No <p> tags, look for other structure\n",
    "        text = soup.get_text()\n",
    "        # Try to detect natural paragraph breaks (double+ newlines)\n",
    "        text = re.sub(r'\\n\\s*\\n\\s*\\n+', '\\n\\n', text)  # Normalize multiple newlines to double\n",
    "        text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)   # Single newlines become spaces\n",
    "        return text.strip(), \"NATURAL_BREAKS\"\n",
    "\n",
    "extracted, method = extract_paragraphs_properly(soup)\n",
    "\n",
    "print(f\"\\nMethod used: {method}\")\n",
    "print(f\"Extracted length: {len(extracted)} characters\")\n",
    "print(f\"Paragraph breaks (\\\\n\\\\n): {extracted.count(chr(10)+chr(10))}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"Sample of properly extracted text:\")\n",
    "print(\"-\" * 70)\n",
    "print(extracted[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ced22b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION: ACTUAL TEACHING CONTENT\n",
      "======================================================================\n",
      "\n",
      "Examining teaching chapter: Clear_Light_of_Bliss_Text_2019-08-43.xhtml\n",
      "\n",
      "Method: HTML_P_TAGS\n",
      "Estimated paragraphs: 2\n",
      "Total characters: 26\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "First 3 paragraphs of teaching content:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[Paragraph 1] (10 chars)\n",
      "page break\n",
      "\n",
      "[Paragraph 2] (14 chars)\n",
      "Losang Trinlay\n"
     ]
    }
   ],
   "source": [
    "# Verify on a TEACHING chapter (not front matter)\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VERIFICATION: ACTUAL TEACHING CONTENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Try to find a teaching chapter (usually mid-book)\n",
    "teaching_item = items[len(items)//2] if len(items) > 10 else items[-1]\n",
    "\n",
    "print(f\"\\nExamining teaching chapter: {teaching_item.get_name()}\")\n",
    "\n",
    "raw_html = teaching_item.get_content().decode('utf-8', errors='replace')\n",
    "soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "extracted, method = extract_paragraphs_properly(soup)\n",
    "\n",
    "para_count = extracted.count('\\n\\n') + 1  # Double newlines + 1 = paragraph count\n",
    "\n",
    "print(f\"\\nMethod: {method}\")\n",
    "print(f\"Estimated paragraphs: {para_count}\")\n",
    "print(f\"Total characters: {len(extracted)}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 70)\n",
    "print(\"First 3 paragraphs of teaching content:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "paragraphs = extracted.split('\\n\\n')\n",
    "for i, para in enumerate(paragraphs[:3], 1):\n",
    "    print(f\"\\n[Paragraph {i}] ({len(para)} chars)\")\n",
    "    print(para[:300] + \"...\" if len(para) > 300 else para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2ec9c242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPLORATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "✓ VERIFIED: Paragraph structure EXISTS in EPUB\n",
      "✓ Method: HTML_P_TAGS\n",
      "✓ Paragraphs detected: 2\n",
      "✓ Previous extraction DESTROYED this structure with re.sub(r'\\s+', ' ')\n",
      "\n",
      "======================================================================\n",
      "RECOMMENDATION\n",
      "======================================================================\n",
      "\n",
      "1. ✓ EPUBs have paragraph structure\n",
      "2. ✓ We can extract it properly\n",
      "3. ✓ Proceed with full re-extraction using the corrected method\n",
      "\n",
      "Ready to create full extraction + embedding pipeline.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final verdict\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXPLORATION SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n✓ VERIFIED: Paragraph structure EXISTS in EPUB\")\n",
    "print(f\"✓ Method: {method}\")\n",
    "print(f\"✓ Paragraphs detected: {para_count}\")\n",
    "print(f\"✓ Previous extraction DESTROYED this structure with re.sub(r'\\\\s+', ' ')\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n1. ✓ EPUBs have paragraph structure\")\n",
    "print(\"2. ✓ We can extract it properly\")\n",
    "print(\"3. ✓ Proceed with full re-extraction using the corrected method\")\n",
    "print(\"\\nReady to create full extraction + embedding pipeline.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4a2cf877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPREHENSIVE DIAGNOSTIC - SCAN ALL CHAPTERS\n",
      "======================================================================\n",
      "\n",
      "Analyzed 89 sections\n",
      "\n",
      "Top 10 sections by content size:\n",
      "----------------------------------------------------------------------\n",
      "Idx   <p>    Chars    \\n\\n   Name                                    \n",
      "----------------------------------------------------------------------\n",
      "43    94     45846    5      Clear_Light_of_Bliss_Text_2019-08-42.xht\n",
      "31    77     44875    5      Clear_Light_of_Bliss_Text_2019-08-30.xht\n",
      "80    154    37713    4      Clear_Light_of_Bliss_Text_2019-08-79.xht\n",
      "39    46     29830    5      Clear_Light_of_Bliss_Text_2019-08-38.xht\n",
      "59    51     27623    4      Clear_Light_of_Bliss_Text_2019-08-58.xht\n",
      "84    1109   23952    6      Clear_Light_of_Bliss_Text_2019-08-83.xht\n",
      "65    59     23709    4      Clear_Light_of_Bliss_Text_2019-08-64.xht\n",
      "63    42     19505    4      Clear_Light_of_Bliss_Text_2019-08-62.xht\n",
      "35    72     18123    4      Clear_Light_of_Bliss_Text_2019-08-34.xht\n",
      "12    82     16767    4      Clear_Light_of_Bliss_Text_2019-08-11.xht\n",
      "\n",
      "======================================================================\n",
      "DETAILED LOOK AT LARGEST TEACHING CHAPTER\n",
      "======================================================================\n",
      "\n",
      "Chapter: Clear_Light_of_Bliss_Text_2019-08-42.xhtml\n",
      "Characters: 45846\n",
      "<p> tags: 94\n",
      "\n",
      "First 5 paragraphs from this chapter:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "[Para 1] (10 chars)\n",
      "page break\n",
      "\n",
      "[Para 2] (44 chars)\n",
      "MIXING WITH THE EMANATION BODY DURING WAKING\n",
      "\n",
      "[Para 3] (186 chars)\n",
      "At this point, we are still in the form of the white Enjoyment Body of our personal Deity. We understand that this body and our normal physical body are totally different and then think:\n",
      "\n",
      "[Para 4] (151 chars)\n",
      "If I remain in this state, ordinary beings will not be able to see me and so I will be unable to help them pass beyond suffering and attain Buddhahood.\n",
      "\n",
      "[Para 5] (199 chars)\n",
      "With this thought, and motivated by bodhichitta, we then make a strong determination to take an Emanation Body that can be perceived by ordinary beings so that we can be of maximum benefit to others.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# COMPREHENSIVE DIAGNOSTIC - Multiple Chapters\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"COMPREHENSIVE DIAGNOSTIC - SCAN ALL CHAPTERS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "chapter_stats = []\n",
    "\n",
    "for i, item in enumerate(items):\n",
    "    try:\n",
    "        raw_html = item.get_content().decode('utf-8', errors='replace')\n",
    "        soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "        \n",
    "        # Count different structural elements\n",
    "        p_tags = len(soup.find_all('p'))\n",
    "        div_tags = len(soup.find_all('div'))\n",
    "        br_tags = len(soup.find_all('br'))\n",
    "        \n",
    "        # Get text and count natural breaks\n",
    "        text = soup.get_text()\n",
    "        double_newlines = text.count('\\n\\n')\n",
    "        char_count = len(text)\n",
    "        \n",
    "        chapter_stats.append({\n",
    "            'index': i,\n",
    "            'name': item.get_name(),\n",
    "            'p_tags': p_tags,\n",
    "            'div_tags': div_tags,\n",
    "            'br_tags': br_tags,\n",
    "            'double_newlines': double_newlines,\n",
    "            'char_count': char_count\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\nAnalyzed {len(chapter_stats)} sections\")\n",
    "print(\"\\nTop 10 sections by content size:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Fixed header line - moved backslash out of f-string\n",
    "newline_label = \"\\\\n\\\\n\"\n",
    "print(f\"{'Idx':<5} {'<p>':<6} {'Chars':<8} {newline_label:<6} {'Name':<40}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Sort by character count to find substantial teaching chapters\n",
    "sorted_stats = sorted(chapter_stats, key=lambda x: x['char_count'], reverse=True)[:10]\n",
    "for stat in sorted_stats:\n",
    "    print(f\"{stat['index']:<5} {stat['p_tags']:<6} {stat['char_count']:<8} {stat['double_newlines']:<6} {stat['name'][:40]:<40}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DETAILED LOOK AT LARGEST TEACHING CHAPTER\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get the chapter with most content\n",
    "largest = sorted_stats[0]\n",
    "largest_item = items[largest['index']]\n",
    "\n",
    "print(f\"\\nChapter: {largest['name']}\")\n",
    "print(f\"Characters: {largest['char_count']}\")\n",
    "print(f\"<p> tags: {largest['p_tags']}\")\n",
    "\n",
    "raw_html = largest_item.get_content().decode('utf-8', errors='replace')\n",
    "soup = BeautifulSoup(raw_html, 'html.parser')\n",
    "\n",
    "# Show structure\n",
    "paragraphs = soup.find_all('p')\n",
    "if paragraphs:\n",
    "    print(f\"\\nFirst 5 paragraphs from this chapter:\")\n",
    "    print(\"-\" * 70)\n",
    "    for i, p in enumerate(paragraphs[:5], 1):\n",
    "        text = p.get_text().strip()\n",
    "        print(f\"\\n[Para {i}] ({len(text)} chars)\")\n",
    "        print(text[:200] + \"...\" if len(text) > 200 else text)\n",
    "else:\n",
    "    print(\"\\n⚠️ NO <p> TAGS FOUND - checking text structure...\")\n",
    "    text = soup.get_text()\n",
    "    print(f\"Raw text sample:\\n{repr(text[:500])}\")\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
