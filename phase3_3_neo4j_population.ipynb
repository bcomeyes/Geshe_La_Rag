{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3.3: Neo4j Graph Database Population (CORRECTED)\n",
    "# Buddhist RAG System - Clear Light of Bliss\n",
    "\n",
    "This version has been corrected to match your actual JSON file structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Neo4j Python Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: neo4j in /home/matt/anaconda3/envs/tibetan-ocr/lib/python3.11/site-packages (6.1.0)\n",
      "Requirement already satisfied: pytz in /home/matt/anaconda3/envs/tibetan-ocr/lib/python3.11/site-packages (from neo4j) (2025.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from neo4j import GraphDatabase\n",
    "from typing import Dict, List\n",
    "import time\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration set\n"
     ]
    }
   ],
   "source": [
    "# Neo4j connection\n",
    "NEO4J_URI = \"neo4j://127.0.0.1:7687\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"password\"  # Your actual password\n",
    "\n",
    "# Data files\n",
    "CHECKPOINT_DIR = Path.home() / \"Documents\" / \"gesha_la_rag\" / \"checkpoints\"\n",
    "LAYER1_FILE = CHECKPOINT_DIR / \"06_document_structure_layer1.json\"\n",
    "LAYER2_FILE = CHECKPOINT_DIR / \"07_semantic_relationships.json\"\n",
    "NORMALIZATION_FILE = CHECKPOINT_DIR / \"04b_normalization_map.json\"\n",
    "\n",
    "for filepath in [LAYER1_FILE, LAYER2_FILE, NORMALIZATION_FILE]:\n",
    "    if not filepath.exists():\n",
    "        raise FileNotFoundError(f\"Required file not found: {filepath}\")\n",
    "\n",
    "print(\"✓ Configuration set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Connect to Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully connected to Neo4j!\n"
     ]
    }
   ],
   "source": [
    "class Neo4jConnection:\n",
    "    def __init__(self, uri: str, user: str, password: str):\n",
    "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        \n",
    "    def close(self):\n",
    "        if self.driver:\n",
    "            self.driver.close()\n",
    "            \n",
    "    def test_connection(self):\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"RETURN 1 as test\")\n",
    "            return result.single()[\"test\"] == 1\n",
    "    \n",
    "    def execute_query(self, query: str, parameters: Dict = None):\n",
    "        \"\"\"Execute a Cypher query and return results as a list.\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(query, parameters or {})\n",
    "            return list(result)  # Convert to list BEFORE session closes\n",
    "        \n",
    "neo4j_conn = Neo4jConnection(NEO4J_URI, NEO4J_USER, NEO4J_PASSWORD)\n",
    "\n",
    "if neo4j_conn.test_connection():\n",
    "    print(\"✓ Successfully connected to Neo4j!\")\n",
    "else:\n",
    "    print(\"✗ Connection failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating schema...\n",
      "  ✓ book_id\n",
      "  ✓ chapter_id\n",
      "  ✓ paragraph_id\n",
      "  ✓ concept_canonical\n",
      "  ✓ paragraph_chapter\n",
      "  ✓ paragraph_citation\n",
      "✓ Schema complete\n"
     ]
    }
   ],
   "source": [
    "def create_schema(conn):\n",
    "    schema_queries = [\n",
    "        \"CREATE CONSTRAINT book_id IF NOT EXISTS FOR (b:Book) REQUIRE b.book_id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT chapter_id IF NOT EXISTS FOR (c:Chapter) REQUIRE (c.book_id, c.chapter_index) IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT paragraph_id IF NOT EXISTS FOR (p:Paragraph) REQUIRE p.paragraph_id IS UNIQUE\",\n",
    "        \"CREATE CONSTRAINT concept_canonical IF NOT EXISTS FOR (c:Concept) REQUIRE c.canonical_form IS UNIQUE\",\n",
    "        \"CREATE INDEX paragraph_chapter IF NOT EXISTS FOR (p:Paragraph) ON (p.chapter_index)\",\n",
    "        \"CREATE INDEX paragraph_citation IF NOT EXISTS FOR (p:Paragraph) ON (p.citation)\",\n",
    "    ]\n",
    "    \n",
    "    print(\"Creating schema...\")\n",
    "    for query in schema_queries:\n",
    "        try:\n",
    "            conn.execute_query(query)\n",
    "            print(f\"  ✓ {query.split()[2]}\")\n",
    "        except Exception as e:\n",
    "            if \"already exists\" in str(e).lower():\n",
    "                print(f\"  ⊙ {query.split()[2]} (exists)\")\n",
    "            else:\n",
    "                print(f\"  ✗ Error: {e}\")\n",
    "    \n",
    "    print(\"✓ Schema complete\")\n",
    "\n",
    "create_schema(neo4j_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Load Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Layer 1...\n",
      "  ✓ 33 chapters\n",
      "  ✓ 3449 paragraphs\n",
      "\n",
      "Loading Layer 2...\n",
      "  ✓ 683 relationships\n",
      "  ✓ 50 concepts\n",
      "\n",
      "Loading normalization...\n",
      "  ✓ 76 canonical concepts\n"
     ]
    }
   ],
   "source": [
    "# Load Layer 1\n",
    "print(\"Loading Layer 1...\")\n",
    "with open(LAYER1_FILE, 'r', encoding='utf-8') as f:\n",
    "    layer1_data = json.load(f)\n",
    "print(f\"  ✓ {layer1_data['total_chapters']} chapters\")\n",
    "print(f\"  ✓ {layer1_data['total_paragraphs']} paragraphs\")\n",
    "\n",
    "# Load Layer 2\n",
    "print(\"\\nLoading Layer 2...\")\n",
    "with open(LAYER2_FILE, 'r', encoding='utf-8') as f:\n",
    "    layer2_data = json.load(f)\n",
    "print(f\"  ✓ {len(layer2_data['relationships'])} relationships\")\n",
    "print(f\"  ✓ {layer2_data['metadata']['unique_concepts']} concepts\")\n",
    "\n",
    "# Load normalization\n",
    "print(\"\\nLoading normalization...\")\n",
    "with open(NORMALIZATION_FILE, 'r', encoding='utf-8') as f:\n",
    "    normalization_map = json.load(f)\n",
    "print(f\"  ✓ {normalization_map['metadata']['total_concepts']} canonical concepts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Populate Layer 1 - Document Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "POPULATING LAYER 1\n",
      "======================================================================\n",
      "\n",
      "1. Creating Book node...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Created: Clear Light of Bliss\n",
      "\n",
      "2. Creating 33 chapters...\n",
      "  ... 10 chapters\n",
      "  ... 20 chapters\n",
      "  ... 30 chapters\n",
      "  ✓ All chapters created\n",
      "\n",
      "3. Creating 3449 paragraphs (1-2 min)...\n",
      "  ... 500/3449 (72/sec)\n",
      "  ... 1000/3449 (76/sec)\n",
      "  ... 1500/3449 (77/sec)\n",
      "  ... 2000/3449 (79/sec)\n",
      "  ... 2500/3449 (81/sec)\n",
      "  ... 3000/3449 (83/sec)\n",
      "  ✓ All paragraphs created in 40.5s\n",
      "\n",
      "✓ Layer 1 complete!\n"
     ]
    }
   ],
   "source": [
    "def populate_layer1(conn, data):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"POPULATING LAYER 1\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create Book\n",
    "    print(\"\\n1. Creating Book node...\")\n",
    "    book_query = \"\"\"\n",
    "    MERGE (b:Book {book_id: $book_id})\n",
    "    SET b.title = $title,\n",
    "        b.total_chapters = $total_chapters,\n",
    "        b.total_paragraphs = $total_paragraphs\n",
    "    RETURN b\n",
    "    \"\"\"\n",
    "    conn.execute_query(book_query, {\n",
    "        'book_id': data['book_id'],\n",
    "        'title': data['book_title'],\n",
    "        'total_chapters': data['total_chapters'],\n",
    "        'total_paragraphs': data['total_paragraphs']\n",
    "    })\n",
    "    print(f\"  ✓ Created: {data['book_title']}\")\n",
    "    \n",
    "    # Create Chapters\n",
    "    print(f\"\\n2. Creating {data['total_chapters']} chapters...\")\n",
    "    chapter_query = \"\"\"\n",
    "    MATCH (b:Book {book_id: $book_id})\n",
    "    MERGE (c:Chapter {book_id: $book_id, chapter_index: $chapter_index})\n",
    "    SET c.title = $title,\n",
    "        c.paragraph_count = $paragraph_count\n",
    "    MERGE (b)-[:HAS_CHAPTER]->(c)\n",
    "    RETURN c\n",
    "    \"\"\"\n",
    "    \n",
    "    for chapter in data['chapters']:\n",
    "        conn.execute_query(chapter_query, {\n",
    "            'book_id': data['book_id'],\n",
    "            'chapter_index': chapter['chapter_index'],\n",
    "            'title': chapter.get('chapter_title', f\"Chapter {chapter['chapter_index']}\"),\n",
    "            'paragraph_count': len(chapter['paragraphs'])\n",
    "        })\n",
    "        if (chapter['chapter_index'] + 1) % 10 == 0:\n",
    "            print(f\"  ... {chapter['chapter_index'] + 1} chapters\")\n",
    "    \n",
    "    print(f\"  ✓ All chapters created\")\n",
    "    \n",
    "    # Create Paragraphs\n",
    "    print(f\"\\n3. Creating {data['total_paragraphs']} paragraphs (1-2 min)...\")\n",
    "    paragraph_query = \"\"\"\n",
    "    MATCH (c:Chapter {book_id: $book_id, chapter_index: $chapter_index})\n",
    "    CREATE (p:Paragraph {\n",
    "        paragraph_id: $paragraph_id,\n",
    "        citation: $citation,\n",
    "        text: $text,\n",
    "        chapter_index: $chapter_index,\n",
    "        paragraph_index: $paragraph_index,\n",
    "        structural_role: $structural_role,\n",
    "        section_index: $section_index,\n",
    "        heading_level: $heading_level\n",
    "    })\n",
    "    CREATE (c)-[:HAS_PARAGRAPH]->(p)\n",
    "    RETURN p\n",
    "    \"\"\"\n",
    "    \n",
    "    total = 0\n",
    "    start = time.time()\n",
    "    \n",
    "    for chapter in data['chapters']:\n",
    "        for para in chapter['paragraphs']:\n",
    "            conn.execute_query(paragraph_query, {\n",
    "                'book_id': data['book_id'],\n",
    "                'chapter_index': chapter['chapter_index'],\n",
    "                'paragraph_id': para['paragraph_id'],\n",
    "                'citation': para['citation'],\n",
    "                'text': para['text'],\n",
    "                'paragraph_index': para['paragraph_index'],\n",
    "                'structural_role': para.get('structural_role', 'BODY'),\n",
    "                'section_index': para.get('section_index'),\n",
    "                'heading_level': para.get('heading_level')\n",
    "            })\n",
    "            \n",
    "            total += 1\n",
    "            if total % 500 == 0:\n",
    "                rate = total / (time.time() - start)\n",
    "                print(f\"  ... {total}/{data['total_paragraphs']} ({rate:.0f}/sec)\")\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"  ✓ All paragraphs created in {elapsed:.1f}s\")\n",
    "    print(\"\\n✓ Layer 1 complete!\")\n",
    "\n",
    "populate_layer1(neo4j_conn, layer1_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Populate Layer 2 - Semantic Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "POPULATING LAYER 2\n",
      "======================================================================\n",
      "\n",
      "1. Creating 50 concepts...\n",
      "  ✓ All concepts created\n",
      "\n",
      "2. Creating 683 relationships...\n",
      "  ... 100/683 (39/sec)\n",
      "  ... 200/683 (53/sec)\n",
      "  ... 300/683 (59/sec)\n",
      "  ... 400/683 (63/sec)\n",
      "  ... 500/683 (66/sec)\n",
      "  ... 600/683 (68/sec)\n",
      "  ✓ All relationships created in 9.8s\n",
      "\n",
      "  Relationship types:\n",
      "    - OF: 265\n",
      "    - AND: 124\n",
      "    - ON: 32\n",
      "    - DEPENDS_UPON: 27\n",
      "    - MIXING_WITH: 26\n",
      "    - DISSOLVE_WITHIN: 24\n",
      "    - KNOWN_AS: 23\n",
      "    - MEDITATING_ON: 22\n",
      "    - WITH: 16\n",
      "    - FREE_FROM: 15\n",
      "    - EMPTY_OF: 13\n",
      "    - ARISE_FROM: 11\n",
      "    - DISSOLVES_INTO: 9\n",
      "    - FOCUSED_ON: 7\n",
      "    - EXPLAINED_IN: 6\n",
      "    - MOUNTED_UPON: 6\n",
      "    - ARISES_FROM: 6\n",
      "    - ENGAGING_IN: 5\n",
      "    - ASSOCIATED_WITH: 5\n",
      "    - DEPENDING_UPON: 5\n",
      "    - RELYING_UPON: 5\n",
      "    - INSEPARABLE_FROM: 5\n",
      "    - THROUGH: 3\n",
      "    - BEFORE: 3\n",
      "    - ATTAINED_IN: 3\n",
      "    - WITHIN: 2\n",
      "    - INDICATIVE_OF: 2\n",
      "    - FOR: 2\n",
      "    - ACCUSTOMED_TO: 2\n",
      "    - DURING: 2\n",
      "    - INCLUDED_WITHIN: 2\n",
      "    - FROM: 2\n",
      "    - DISSOLVING_INTO: 1\n",
      "    - OR: 1\n",
      "    - UPON: 1\n",
      "\n",
      "✓ Layer 2 complete!\n"
     ]
    }
   ],
   "source": [
    "def populate_layer2(conn, data):\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"POPULATING LAYER 2\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Create Concepts\n",
    "    print(f\"\\n1. Creating {layer2_data['metadata']['unique_concepts']} concepts...\")\n",
    "    concept_query = \"\"\"\n",
    "    MERGE (c:Concept {canonical_form: $canonical_form})\n",
    "    SET c.display_name = $display_name,\n",
    "        c.mention_count = $mention_count\n",
    "    RETURN c\n",
    "    \"\"\"\n",
    "    \n",
    "    for concept_name, count in data['concept_inventory'].items():\n",
    "        display_name = concept_name.replace('_', ' ').title()\n",
    "        conn.execute_query(concept_query, {\n",
    "            'canonical_form': concept_name,\n",
    "            'display_name': display_name,\n",
    "            'mention_count': count\n",
    "        })\n",
    "    \n",
    "    print(f\"  ✓ All concepts created\")\n",
    "    \n",
    "    # Create Relationships\n",
    "    print(f\"\\n2. Creating {len(data['relationships'])} relationships...\")\n",
    "    \n",
    "    counts = {}\n",
    "    start = time.time()\n",
    "    \n",
    "    for idx, rel in enumerate(data['relationships']):\n",
    "        rel_type = rel['relation'].upper().replace(' ', '_').replace('-', '_')\n",
    "        \n",
    "        rel_query = f\"\"\"\n",
    "        MATCH (subj:Concept {{canonical_form: $subject}})\n",
    "        MATCH (obj:Concept {{canonical_form: $object}})\n",
    "        CREATE (subj)-[r:{rel_type} {{\n",
    "            source_paragraph_id: $source_paragraph_id,\n",
    "            source_chapter: $source_chapter,\n",
    "            relation_type: $relation_type,\n",
    "            source_citation: $source_citation\n",
    "        }}]->(obj)\n",
    "        RETURN r\n",
    "        \"\"\"\n",
    "        \n",
    "        conn.execute_query(rel_query, {\n",
    "            'subject': rel['subject'],\n",
    "            'object': rel['object'],\n",
    "            'source_paragraph_id': rel['source']['paragraph_id'],\n",
    "            'source_chapter': rel['source']['chapter_index'],\n",
    "            'relation_type': rel['relation_type'],\n",
    "            'source_citation': rel['source']['citation']\n",
    "        })\n",
    "        \n",
    "        counts[rel_type] = counts.get(rel_type, 0) + 1\n",
    "        \n",
    "        if (idx + 1) % 100 == 0:\n",
    "            rate = (idx + 1) / (time.time() - start)\n",
    "            print(f\"  ... {idx + 1}/{len(data['relationships'])} ({rate:.0f}/sec)\")\n",
    "    \n",
    "    elapsed = time.time() - start\n",
    "    print(f\"  ✓ All relationships created in {elapsed:.1f}s\")\n",
    "    \n",
    "    print(\"\\n  Relationship types:\")\n",
    "    for rel_type, count in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f\"    - {rel_type}: {count}\")\n",
    "    \n",
    "    print(\"\\n✓ Layer 2 complete!\")\n",
    "\n",
    "populate_layer2(neo4j_conn, layer2_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Validation Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VALIDATION\n",
      "======================================================================\n",
      "\n",
      "1. Node counts:\n",
      "   Paragraph: 3449\n",
      "   Concept: 50\n",
      "   Chapter: 33\n",
      "   Book: 1\n",
      "\n",
      "2. Relationship counts (top 10):\n",
      "   HAS_PARAGRAPH: 3449\n",
      "   OF: 265\n",
      "   AND: 124\n",
      "   HAS_CHAPTER: 33\n",
      "   ON: 32\n",
      "   DEPENDS_UPON: 27\n",
      "   MIXING_WITH: 26\n",
      "   DISSOLVE_WITHIN: 24\n",
      "   KNOWN_AS: 23\n",
      "   MEDITATING_ON: 22\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Node counts\n",
    "print(\"\\n1. Node counts:\")\n",
    "result = neo4j_conn.execute_query(\"\"\"\n",
    "MATCH (n)\n",
    "RETURN labels(n)[0] as label, count(n) as count\n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "for record in list(result):  # Convert to list\n",
    "    print(f\"   {record['label']}: {record['count']}\")\n",
    "\n",
    "# Relationship counts\n",
    "print(\"\\n2. Relationship counts (top 10):\")\n",
    "result = neo4j_conn.execute_query(\"\"\"\n",
    "MATCH ()-[r]->()\n",
    "RETURN type(r) as type, count(r) as count\n",
    "ORDER BY count DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "for record in list(result):  # Convert to list\n",
    "    print(f\"   {record['type']}: {record['count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Example relationships with provenance:\n",
      "\n",
      "   clear_light --[KNOWN_AS]--> mahamudra\n",
      "   Source: CLB.7.§1.p40\n",
      "   Chapter: Introduction and Preliminaries\n",
      "   Text: The second stage of causal-time Mahamudra is the Mahamudra that is theunion of the two truths: the c...\n",
      "\n",
      "   clear_light --[OF]--> completion_stage\n",
      "   Source: CLB.7.§6.p104\n",
      "   Chapter: Introduction and Preliminaries\n",
      "   Text: This is the brief meditation onbringing death into the path to the Truth Body. It functions principa...\n",
      "\n",
      "   clear_light --[OF]--> sleep\n",
      "   Source: CLB.8.§10.p86\n",
      "   Chapter: Channels, Winds and Drops\n",
      "   Text: At death we need to be able to practise three special methods:bringing theclear light of death into ...\n"
     ]
    }
   ],
   "source": [
    "# Provenance test\n",
    "print(\"\\n3. Example relationships with provenance:\")\n",
    "result = neo4j_conn.execute_query(\"\"\"\n",
    "MATCH (c1:Concept {canonical_form: 'clear_light'})-[r]->(c2:Concept)\n",
    "MATCH (p:Paragraph {paragraph_id: r.source_paragraph_id})\n",
    "MATCH (ch:Chapter {chapter_index: p.chapter_index})\n",
    "RETURN c1.canonical_form as subject,\n",
    "       type(r) as relation,\n",
    "       c2.canonical_form as object,\n",
    "       ch.title as chapter,\n",
    "       p.citation as citation,\n",
    "       substring(p.text, 0, 100) as excerpt\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "for record in result:\n",
    "    print(f\"\\n   {record['subject']} --[{record['relation']}]--> {record['object']}\")\n",
    "    print(f\"   Source: {record['citation']}\")\n",
    "    print(f\"   Chapter: {record['chapter']}\")\n",
    "    print(f\"   Text: {record['excerpt']}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Top 10 concepts:\n",
      "   1. Mind: 618\n",
      "   2. Meditation: 350\n",
      "   3. Clear Light: 244\n",
      "   4. Emptiness: 226\n",
      "   5. Illusory Body: 200\n",
      "   6. Central Channel: 197\n",
      "   7. Secret Mantra: 136\n",
      "   8. Mahamudra: 127\n",
      "   9. Inner Fire: 118\n",
      "   10. Sleep: 118\n"
     ]
    }
   ],
   "source": [
    "# Top concepts\n",
    "print(\"\\n4. Top 10 concepts:\")\n",
    "result = neo4j_conn.execute_query(\"\"\"\n",
    "MATCH (c:Concept)\n",
    "RETURN c.display_name as concept, c.mention_count as mentions\n",
    "ORDER BY mentions DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "for idx, record in enumerate(result, 1):\n",
    "    print(f\"   {idx}. {record['concept']}: {record['mentions']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "✓ NEO4J POPULATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "Your Buddhist RAG graph database is ready!\n",
      "  • Book → Chapter → Paragraph structure\n",
      "  • Concept nodes with semantic relationships\n",
      "  • Cross-layer provenance linking\n",
      "\n",
      "Connection: neo4j://127.0.0.1:7687\n",
      "\n",
      "✓ Connection closed\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✓ NEO4J POPULATION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nYour Buddhist RAG graph database is ready!\")\n",
    "print(\"  • Book → Chapter → Paragraph structure\")\n",
    "print(\"  • Concept nodes with semantic relationships\")\n",
    "print(\"  • Cross-layer provenance linking\")\n",
    "print(\"\\nConnection: neo4j://127.0.0.1:7687\")\n",
    "\n",
    "neo4j_conn.close()\n",
    "print(\"\\n✓ Connection closed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tibetan-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
