{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636603fa",
   "metadata": {},
   "source": [
    "# Phase 2.5: Concept Normalization & Coreference Flagging\n",
    "\n",
    "**Purpose**: Two pre-extraction steps that ensure clean data enters the graph.\n",
    "\n",
    "## 1. Concept Normalization\n",
    "Build a canonical form map so that \"Clear Light\", \"clear light\", \"the clear light\" all resolve to one node (`clear_light`) rather than three. This happens at extraction time ‚Äî every entity gets normalized before being written to the output.\n",
    "\n",
    "**Principle**: The EntityRuler *detects* all case variants. But detection is not deduplication. The extraction function currently writes the surface form from the text into the triple. We need it to write the canonical form instead.\n",
    "\n",
    "## 2. Coreference Flagging\n",
    "When the subject or object of an extracted relationship is a pronoun or demonstrative (\"this practice\", \"such a mind\", \"it\"), the relationship is real but the reference is unresolved. Rather than importing garbage into Neo4j or silently dropping data, we flag it:\n",
    "- `resolved: true` ‚Äî both subject and object are known concepts  \n",
    "- `resolved: false` ‚Äî one or both are unresolved references\n",
    "\n",
    "Only resolved relationships enter the graph. Unresolved ones are preserved for future work.\n",
    "\n",
    "**This is the translation table.** Like the lotsƒÅwas who documented every translation choice, we document every normalization choice explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac3ca6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded 80 terms from vocabulary\n",
      "  Categories: ['nouns', 'adj_noun', 'verbs', 'adj_prep']\n",
      "\n",
      "  Terms appearing in multiple categories:\n",
      "    \"inherent existence\" ‚Üí ['nouns', 'adj_noun']\n",
      "    \"white appearance\" ‚Üí ['nouns', 'adj_noun']\n",
      "    \"clear light\" ‚Üí ['nouns', 'adj_noun']\n",
      "    \"inner fire\" ‚Üí ['nouns', 'adj_noun']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "with open('checkpoints/04_final_vocabulary.json') as f:\n",
    "    vocab = json.load(f)\n",
    "\n",
    "# Collect all terms across categories\n",
    "all_terms = []\n",
    "for category, terms in vocab['data'].items():\n",
    "    for term, count in terms:\n",
    "        all_terms.append((term, count, category))\n",
    "\n",
    "# Sort by length descending (longer terms first ‚Äî important for matching)\n",
    "all_terms.sort(key=lambda x: -len(x[0]))\n",
    "\n",
    "print(f\"‚úì Loaded {len(all_terms)} terms from vocabulary\")\n",
    "print(f\"  Categories: {list(vocab['data'].keys())}\")\n",
    "\n",
    "# Show duplicates across categories\n",
    "term_names = [t[0] for t in all_terms]\n",
    "from collections import Counter\n",
    "dupes = {t: c for t, c in Counter(term_names).items() if c > 1}\n",
    "if dupes:\n",
    "    print(f\"\\n  Terms appearing in multiple categories:\")\n",
    "    for term, count in dupes.items():\n",
    "        cats = [cat for t, _, cat in all_terms if t == term]\n",
    "        print(f\"    \\\"{term}\\\" ‚Üí {cats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aabe82",
   "metadata": {},
   "source": [
    "## Build Canonical Form Map\n",
    "\n",
    "Rules for canonical form:\n",
    "1. Lowercase, underscores for spaces: `\"clear light\"` ‚Üí `\"clear_light\"`\n",
    "2. Strip leading articles: `\"the clear light\"` ‚Üí `\"clear_light\"`\n",
    "3. Longer compound terms get their OWN canonical form (not collapsed into a sub-term): `\"ultimate example clear light\"` ‚Üí `\"ultimate_example_clear_light\"` (NOT `\"clear_light\"`)\n",
    "4. Proper nouns keep their identity: `\"Je Tsongkhapa\"` ‚Üí `\"je_tsongkhapa\"`, `\"Heruka\"` ‚Üí `\"heruka\"`\n",
    "5. Every variant we can anticipate gets an explicit entry ‚Äî no guessing at runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e73cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Canonical map built\n",
      "  76 unique concepts\n",
      "  1502 surface form ‚Üí canonical entries\n",
      "\n",
      "Examples:\n",
      "  \"clear light\" ‚Üí \"clear_light\"\n",
      "  \"Clear Light\" ‚Üí \"clear_light\"\n",
      "  \"The clear light\" ‚Üí \"clear_light\"\n",
      "  \"the Clear Light\" ‚Üí \"clear_light\"\n",
      "  \"emptiness\" ‚Üí \"emptiness\"\n",
      "  \"Emptiness\" ‚Üí \"emptiness\"\n",
      "  \"the emptiness\" ‚Üí \"emptiness\"\n",
      "  \"illusory body\" ‚Üí \"illusory_body\"\n",
      "  \"Illusory Body\" ‚Üí \"illusory_body\"\n",
      "  \"The illusory body\" ‚Üí \"illusory_body\"\n",
      "  \"ultimate example clear light\" ‚Üí \"ultimate_example_clear_light\"\n",
      "  \"je tsongkhapa\" ‚Üí \"je_tsongkhapa\"\n",
      "  \"Je Tsongkhapa\" ‚Üí \"je_tsongkhapa\"\n"
     ]
    }
   ],
   "source": [
    "def make_canonical(term):\n",
    "    \"\"\"Convert a term to its canonical form.\"\"\"\n",
    "    # Strip leading articles\n",
    "    t = re.sub(r'^(the|a|an)\\s+', '', term.strip(), flags=re.IGNORECASE)\n",
    "    # Lowercase, replace spaces with underscores\n",
    "    t = t.lower().strip().replace(' ', '_')\n",
    "    # Remove any double underscores\n",
    "    t = re.sub(r'_+', '_', t)\n",
    "    return t\n",
    "\n",
    "\n",
    "# Build the map: every possible surface form ‚Üí canonical form\n",
    "canonical_map = {}\n",
    "\n",
    "# Get unique terms (deduplicated across categories)\n",
    "unique_terms = list(dict.fromkeys(t[0] for t in all_terms))  # preserves order, removes dupes\n",
    "\n",
    "for term in unique_terms:\n",
    "    canonical = make_canonical(term)\n",
    "    \n",
    "    # Generate all anticipated surface forms\n",
    "    variants = set()\n",
    "    \n",
    "    # Base form\n",
    "    variants.add(term)                          # \"clear light\"\n",
    "    variants.add(term.lower())                  # \"clear light\"  \n",
    "    variants.add(term.capitalize())             # \"Clear light\"\n",
    "    variants.add(term.title())                  # \"Clear Light\"\n",
    "    variants.add(term.upper())                  # \"CLEAR LIGHT\"\n",
    "    \n",
    "    # With leading article\n",
    "    for article in ['the', 'a', 'an', 'The', 'A', 'An', 'THE', 'A', 'AN']:\n",
    "        variants.add(f\"{article} {term}\")\n",
    "        variants.add(f\"{article} {term.lower()}\")\n",
    "        variants.add(f\"{article} {term.title()}\")\n",
    "    \n",
    "    # With trailing punctuation (sometimes entities pick up trailing periods/commas)\n",
    "    base_variants = list(variants)\n",
    "    for v in base_variants:\n",
    "        variants.add(v.rstrip('.,;:'))\n",
    "    \n",
    "    # Map all variants to canonical\n",
    "    for v in variants:\n",
    "        if v.strip():\n",
    "            canonical_map[v] = canonical\n",
    "\n",
    "print(f\"‚úì Canonical map built\")\n",
    "print(f\"  {len(unique_terms)} unique concepts\")\n",
    "print(f\"  {len(canonical_map)} surface form ‚Üí canonical entries\")\n",
    "\n",
    "# Show some examples\n",
    "print(f\"\\nExamples:\")\n",
    "examples = ['clear light', 'Clear Light', 'The clear light', 'the Clear Light',\n",
    "            'emptiness', 'Emptiness', 'the emptiness',\n",
    "            'illusory body', 'Illusory Body', 'The illusory body',\n",
    "            'ultimate example clear light', 'je tsongkhapa', 'Je Tsongkhapa']\n",
    "for ex in examples:\n",
    "    canon = canonical_map.get(ex, f'??? NOT FOUND: {ex}')\n",
    "    print(f\"  \\\"{ex}\\\" ‚Üí \\\"{canon}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9ce52f",
   "metadata": {},
   "source": [
    "## Verify: No Collisions\n",
    "\n",
    "Check that longer compound terms don't accidentally map to shorter terms. \"ultimate example clear light\" must NOT resolve to \"clear_light\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445c7ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì No collisions ‚Äî each canonical form maps to exactly one concept\n",
      "\n",
      "Compound term verification:\n",
      "  ‚úì \"clear light\" ‚Üí \"clear_light\" (expected \"clear_light\")\n",
      "  ‚úì \"ultimate example clear light\" ‚Üí \"ultimate_example_clear_light\" (expected \"ultimate_example_clear_light\")\n",
      "  ‚úì \"great bliss\" ‚Üí \"great_bliss\" (expected \"great_bliss\")\n",
      "  ‚úì \"spontaneous great bliss\" ‚Üí \"spontaneous_great_bliss\" (expected \"spontaneous_great_bliss\")\n",
      "  ‚úì \"subtle mind\" ‚Üí \"subtle_mind\" (expected \"subtle_mind\")\n",
      "  ‚úì \"isolated mind\" ‚Üí \"isolated_mind\" (expected \"isolated_mind\")\n"
     ]
    }
   ],
   "source": [
    "# Check that each canonical form maps to exactly one concept\n",
    "canonical_to_terms = defaultdict(set)\n",
    "for term in unique_terms:\n",
    "    canon = make_canonical(term)\n",
    "    canonical_to_terms[canon].add(term)\n",
    "\n",
    "collisions = {c: terms for c, terms in canonical_to_terms.items() if len(terms) > 1}\n",
    "\n",
    "if collisions:\n",
    "    print(f\"‚ö†Ô∏è  {len(collisions)} canonical forms map to multiple terms:\")\n",
    "    for canon, terms in collisions.items():\n",
    "        print(f\"  \\\"{canon}\\\" ‚Üê {terms}\")\n",
    "    print(f\"\\n  These need manual disambiguation in the map.\")\n",
    "else:\n",
    "    print(f\"‚úì No collisions ‚Äî each canonical form maps to exactly one concept\")\n",
    "\n",
    "# Verify compound terms are distinct\n",
    "compound_checks = [\n",
    "    (\"clear light\", \"clear_light\"),\n",
    "    (\"ultimate example clear light\", \"ultimate_example_clear_light\"),\n",
    "    (\"great bliss\", \"great_bliss\"),\n",
    "    (\"spontaneous great bliss\", \"spontaneous_great_bliss\"),\n",
    "    (\"subtle mind\", \"subtle_mind\"),\n",
    "    (\"isolated mind\", \"isolated_mind\"),\n",
    "]\n",
    "print(f\"\\nCompound term verification:\")\n",
    "for term, expected in compound_checks:\n",
    "    actual = make_canonical(term)\n",
    "    status = \"‚úì\" if actual == expected else \"‚úó\"\n",
    "    print(f\"  {status} \\\"{term}\\\" ‚Üí \\\"{actual}\\\" (expected \\\"{expected}\\\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b074ba",
   "metadata": {},
   "source": [
    "## Coreference Detection Patterns\n",
    "\n",
    "Define the patterns that indicate an unresolved reference. When we see these as the subject or object of a relationship, we flag the relationship as `resolved: false`.\n",
    "\n",
    "These are not all pronouns ‚Äî Buddhist text has specific demonstrative patterns like \"this practice\", \"such a mind\", \"that realization\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8eefa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coreference detection tests:\n",
      "  ‚úì \"this practice\" ‚Üí UNRESOLVED\n",
      "  ‚úó \"this meditation\" ‚Üí resolved\n",
      "  ‚úì \"such a mind\" ‚Üí UNRESOLVED\n",
      "  ‚úì \"these winds\" ‚Üí UNRESOLVED\n",
      "  ‚úì \"that realization\" ‚Üí UNRESOLVED\n",
      "  ‚úì \"it\" ‚Üí UNRESOLVED\n",
      "  ‚úì \"they\" ‚Üí UNRESOLVED\n",
      "  ‚úó \"the above meditation\" ‚Üí resolved\n",
      "  ‚úì \"clear light\" ‚Üí resolved\n",
      "  ‚úì \"emptiness\" ‚Üí resolved\n",
      "  ‚úì \"inner fire\" ‚Üí resolved\n",
      "  ‚úì \"central channel\" ‚Üí resolved\n",
      "  ‚úì \"the clear light\" ‚Üí resolved\n",
      "\n",
      "‚ö†Ô∏è  Some tests failed ‚Äî review patterns above\n"
     ]
    }
   ],
   "source": [
    "# ‚îÄ‚îÄ Coreference detection patterns ‚îÄ‚îÄ\n",
    "# If a subject or object STARTS WITH one of these, it's likely unresolved\n",
    "\n",
    "DEMONSTRATIVE_PREFIXES = [\n",
    "    'this ', 'that ', 'these ', 'those ',\n",
    "    'such ', 'such a ', 'such an ',\n",
    "    'the above ', 'the same ', 'the following ',\n",
    "    'the former ', 'the latter ',\n",
    "]\n",
    "\n",
    "# If a subject or object IS one of these exactly, it's definitely unresolved\n",
    "PRONOUN_SUBJECTS = {\n",
    "    'it', 'they', 'them', 'he', 'she', 'we', 'its',\n",
    "    'this', 'that', 'these', 'those',\n",
    "    'the former', 'the latter',\n",
    "    'both', 'each', 'all',\n",
    "}\n",
    "\n",
    "def is_unresolved_reference(text):\n",
    "    \"\"\"\n",
    "    Check if a text string is likely an unresolved coreference.\n",
    "    \n",
    "    Returns:\n",
    "        True if this looks like a pronoun or demonstrative reference\n",
    "        False if this looks like a real concept\n",
    "    \"\"\"\n",
    "    t = text.strip().lower()\n",
    "    \n",
    "    # Exact pronoun match\n",
    "    if t in PRONOUN_SUBJECTS:\n",
    "        return True\n",
    "    \n",
    "    # Starts with demonstrative\n",
    "    for prefix in DEMONSTRATIVE_PREFIXES:\n",
    "        if t.startswith(prefix):\n",
    "            # But NOT if the full phrase is a known concept\n",
    "            # e.g., \"this very subtle mind\" is unresolved, \n",
    "            #        but we need to check it's not in our vocabulary\n",
    "            remainder = t[len(prefix):]\n",
    "            if remainder not in {term.lower() for term in unique_terms}:\n",
    "                return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "# Test cases\n",
    "test_refs = [\n",
    "    # Should be UNRESOLVED\n",
    "    (\"this practice\", True),\n",
    "    (\"this meditation\", True),\n",
    "    (\"such a mind\", True),\n",
    "    (\"these winds\", True),\n",
    "    (\"that realization\", True),\n",
    "    (\"it\", True),\n",
    "    (\"they\", True),\n",
    "    (\"the above meditation\", True),\n",
    "    \n",
    "    # Should be RESOLVED (real concepts)\n",
    "    (\"clear light\", False),\n",
    "    (\"emptiness\", False),\n",
    "    (\"inner fire\", False),\n",
    "    (\"central channel\", False),\n",
    "    (\"the clear light\", False),  # article + known concept = resolved\n",
    "]\n",
    "\n",
    "print(\"Coreference detection tests:\")\n",
    "all_pass = True\n",
    "for text, expected_unresolved in test_refs:\n",
    "    actual = is_unresolved_reference(text)\n",
    "    status = \"‚úì\" if actual == expected_unresolved else \"‚úó\"\n",
    "    if actual != expected_unresolved:\n",
    "        all_pass = False\n",
    "    label = \"UNRESOLVED\" if actual else \"resolved\"\n",
    "    print(f\"  {status} \\\"{text}\\\" ‚Üí {label}\")\n",
    "\n",
    "if all_pass:\n",
    "    print(f\"\\n‚úì All coreference tests passed\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Some tests failed ‚Äî review patterns above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5071ec",
   "metadata": {},
   "source": [
    "## Save Normalization Artifacts\n",
    "\n",
    "Save both the canonical map and the coreference patterns so the extraction function can use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abdd793a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved to checkpoints/04b_normalization_map.json (61.4 KB)\n",
      "  76 concepts\n",
      "  1502 surface forms\n",
      "  12 demonstrative prefixes\n",
      "  16 pronoun subjects\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "output = {\n",
    "    'metadata': {\n",
    "        'version': '1.0',\n",
    "        'source_vocabulary': 'checkpoints/04_final_vocabulary.json',\n",
    "        'total_concepts': len(unique_terms),\n",
    "        'total_surface_forms': len(canonical_map),\n",
    "        'description': 'Canonical form map for concept normalization + coreference detection patterns',\n",
    "    },\n",
    "    'canonical_map': canonical_map,\n",
    "    'canonical_to_concept': {make_canonical(t): t for t in unique_terms},\n",
    "    'coreference_patterns': {\n",
    "        'demonstrative_prefixes': DEMONSTRATIVE_PREFIXES,\n",
    "        'pronoun_subjects': sorted(PRONOUN_SUBJECTS),\n",
    "    },\n",
    "}\n",
    "\n",
    "OUTPUT_FILE = 'checkpoints/04b_normalization_map.json'\n",
    "with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "file_size = os.path.getsize(OUTPUT_FILE) / 1024\n",
    "print(f\"‚úì Saved to {OUTPUT_FILE} ({file_size:.1f} KB)\")\n",
    "print(f\"  {len(unique_terms)} concepts\")\n",
    "print(f\"  {len(canonical_map)} surface forms\")\n",
    "print(f\"  {len(DEMONSTRATIVE_PREFIXES)} demonstrative prefixes\")\n",
    "print(f\"  {len(PRONOUN_SUBJECTS)} pronoun subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d33309",
   "metadata": {},
   "source": [
    "## How This Integrates with Extraction\n",
    "\n",
    "Here's how the extraction function will use these artifacts. This is a preview ‚Äî the actual integration happens in the full-book extraction notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95b3b137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction pipeline demo:\n",
      "======================================================================\n",
      "\n",
      "  ‚úì RESOLVED\n",
      "  Raw:        \"Clear Light\" --[is inseparable from]--> \"emptiness\"\n",
      "  Normalized: \"clear_light\" --[is inseparable from]--> \"emptiness\"\n",
      "  Source:     CLB.10.¬ß1.p5\n",
      "\n",
      "  ‚úì RESOLVED\n",
      "  Raw:        \"this meditation\" --[depends upon]--> \"inner fire\"\n",
      "  Normalized: \"this_meditation\" --[depends upon]--> \"inner_fire\"\n",
      "  Source:     CLB.9.¬ß3.p12\n",
      "\n",
      "  ‚úì RESOLVED\n",
      "  Raw:        \"The illusory body\" --[arises from]--> \"clear light\"\n",
      "  Normalized: \"illusory_body\" --[arises from]--> \"clear_light\"\n",
      "  Source:     CLB.15.¬ß2.p8\n",
      "\n",
      "  ‚úó UNRESOLVED\n",
      "  Raw:        \"it\" --[dissolves into]--> \"the central channel\"\n",
      "  Normalized: \"it\" --[dissolves into]--> \"central_channel\"\n",
      "  Source:     CLB.8.¬ß4.p20\n",
      "\n",
      "  ‚úì RESOLVED\n",
      "  Raw:        \"spontaneous great bliss\" --[is empty of]--> \"inherent existence\"\n",
      "  Normalized: \"spontaneous_great_bliss\" --[is empty of]--> \"inherent_existence\"\n",
      "  Source:     CLB.10.¬ß2.p30\n"
     ]
    }
   ],
   "source": [
    "def normalize_concept(surface_form, canonical_map=canonical_map):\n",
    "    \"\"\"\n",
    "    Normalize a concept's surface form to its canonical form.\n",
    "    \n",
    "    Returns the canonical form if found, otherwise returns \n",
    "    a normalized version of the surface form itself.\n",
    "    \"\"\"\n",
    "    # Try exact match first\n",
    "    if surface_form in canonical_map:\n",
    "        return canonical_map[surface_form]\n",
    "    \n",
    "    # Try lowercase\n",
    "    if surface_form.lower() in canonical_map:\n",
    "        return canonical_map[surface_form.lower()]\n",
    "    \n",
    "    # Try stripping articles\n",
    "    stripped = re.sub(r'^(the|a|an)\\s+', '', surface_form, flags=re.IGNORECASE)\n",
    "    if stripped in canonical_map:\n",
    "        return canonical_map[stripped]\n",
    "    if stripped.lower() in canonical_map:\n",
    "        return canonical_map[stripped.lower()]\n",
    "    \n",
    "    # Not in vocabulary ‚Äî return a normalized form but mark as unknown\n",
    "    return make_canonical(surface_form)\n",
    "\n",
    "\n",
    "def process_relationship(subject, relation, obj, paragraph_id, citation):\n",
    "    \"\"\"\n",
    "    Process a single extracted relationship:\n",
    "    1. Normalize subject and object\n",
    "    2. Check for unresolved coreferences\n",
    "    3. Return enriched relationship dict\n",
    "    \"\"\"\n",
    "    subj_normalized = normalize_concept(subject)\n",
    "    obj_normalized = normalize_concept(obj)\n",
    "    \n",
    "    subj_unresolved = is_unresolved_reference(subject)\n",
    "    obj_unresolved = is_unresolved_reference(obj)\n",
    "    \n",
    "    resolved = not (subj_unresolved or obj_unresolved)\n",
    "    \n",
    "    return {\n",
    "        'subject': subj_normalized,\n",
    "        'subject_surface': subject,\n",
    "        'relation': relation,\n",
    "        'object': obj_normalized,\n",
    "        'object_surface': obj,\n",
    "        'resolved': resolved,\n",
    "        'source': {\n",
    "            'paragraph_id': paragraph_id,\n",
    "            'citation': citation,\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ Demo ‚îÄ‚îÄ\n",
    "print(\"Extraction pipeline demo:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "demo_triples = [\n",
    "    (\"Clear Light\", \"is inseparable from\", \"emptiness\", \"clb_ch10_para5\", \"CLB.10.¬ß1.p5\"),\n",
    "    (\"this meditation\", \"depends upon\", \"inner fire\", \"clb_ch9_para12\", \"CLB.9.¬ß3.p12\"),\n",
    "    (\"The illusory body\", \"arises from\", \"clear light\", \"clb_ch15_para8\", \"CLB.15.¬ß2.p8\"),\n",
    "    (\"it\", \"dissolves into\", \"the central channel\", \"clb_ch8_para20\", \"CLB.8.¬ß4.p20\"),\n",
    "    (\"spontaneous great bliss\", \"is empty of\", \"inherent existence\", \"clb_ch10_para30\", \"CLB.10.¬ß2.p30\"),\n",
    "]\n",
    "\n",
    "for subj, rel, obj, pid, cite in demo_triples:\n",
    "    result = process_relationship(subj, rel, obj, pid, cite)\n",
    "    flag = \"‚úì RESOLVED\" if result['resolved'] else \"‚úó UNRESOLVED\"\n",
    "    print(f\"\\n  {flag}\")\n",
    "    print(f\"  Raw:        \\\"{subj}\\\" --[{rel}]--> \\\"{obj}\\\"\")\n",
    "    print(f\"  Normalized: \\\"{result['subject']}\\\" --[{rel}]--> \\\"{result['object']}\\\"\")\n",
    "    print(f\"  Source:     {cite}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30ee76",
   "metadata": {},
   "source": [
    "## üö¶ Validation Gate 2C: Normalization Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c169963d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üö¶ VALIDATION GATE 2C: Normalization Quality\n",
      "======================================================================\n",
      "  ‚úì Canonical map has entries (1502 entries)\n",
      "  ‚úì Core terms normalize correctly\n",
      "  ‚úì Compound terms not collapsed (clear_light ‚â† ultimate_example_clear_light)\n",
      "  ‚úì Coreference detection works\n",
      "  ‚úì No canonical form collisions (0 collisions)\n",
      "  ‚úì 04b_normalization_map.json saved\n",
      "\n",
      "  ‚úÖ GATE 2C PASSED\n",
      "  Normalization map ready. Extraction function can use it.\n",
      "  Next: Full-book extraction with normalization + coreference flagging\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"üö¶ VALIDATION GATE 2C: Normalization Quality\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "checks = []\n",
    "\n",
    "# Check 1: Canonical map exists and has entries\n",
    "checks.append(('Canonical map has entries', len(canonical_map) > 100,\n",
    "               f\"{len(canonical_map)} entries\"))\n",
    "\n",
    "# Check 2: Core terms normalize correctly\n",
    "core_tests = [\n",
    "    (\"Clear light\", \"clear_light\"),\n",
    "    (\"clear light\", \"clear_light\"),\n",
    "    (\"the clear light\", \"clear_light\"),\n",
    "    (\"CLEAR LIGHT\", \"clear_light\"),\n",
    "    (\"emptiness\", \"emptiness\"),\n",
    "    (\"The emptiness\", \"emptiness\"),\n",
    "    (\"illusory body\", \"illusory_body\"),\n",
    "    (\"Illusory Body\", \"illusory_body\"),\n",
    "    (\"ultimate example clear light\", \"ultimate_example_clear_light\"),\n",
    "    (\"je tsongkhapa\", \"je_tsongkhapa\"),\n",
    "    (\"Je Tsongkhapa\", \"je_tsongkhapa\"),\n",
    "]\n",
    "core_pass = True\n",
    "for surface, expected in core_tests:\n",
    "    actual = normalize_concept(surface)\n",
    "    if actual != expected:\n",
    "        core_pass = False\n",
    "        print(f\"  FAIL: \\\"{surface}\\\" ‚Üí \\\"{actual}\\\" (expected \\\"{expected}\\\")\")\n",
    "checks.append(('Core terms normalize correctly', core_pass, ''))\n",
    "\n",
    "# Check 3: Compound terms stay distinct  \n",
    "compound_pass = (normalize_concept(\"clear light\") != normalize_concept(\"ultimate example clear light\"))\n",
    "checks.append(('Compound terms not collapsed', compound_pass,\n",
    "               f\"clear_light ‚â† ultimate_example_clear_light\"))\n",
    "\n",
    "# Check 4: Coreference detection works\n",
    "coref_pass = (\n",
    "    is_unresolved_reference(\"this practice\") == True and\n",
    "    is_unresolved_reference(\"clear light\") == False and\n",
    "    is_unresolved_reference(\"it\") == True and\n",
    "    is_unresolved_reference(\"emptiness\") == False\n",
    ")\n",
    "checks.append(('Coreference detection works', coref_pass, ''))\n",
    "\n",
    "# Check 5: No collision between distinct concepts\n",
    "checks.append(('No canonical form collisions', len(collisions) == 0,\n",
    "               f\"{len(collisions)} collisions\"))\n",
    "\n",
    "# Check 6: Normalization map saved\n",
    "checks.append(('04b_normalization_map.json saved', os.path.exists('checkpoints/04b_normalization_map.json'), ''))\n",
    "\n",
    "all_pass = True\n",
    "for desc, passed, detail in checks:\n",
    "    status = \"‚úì\" if passed else \"‚úó\"\n",
    "    if not passed:\n",
    "        all_pass = False\n",
    "    detail_str = f\" ({detail})\" if detail else \"\"\n",
    "    print(f\"  {status} {desc}{detail_str}\")\n",
    "\n",
    "if all_pass:\n",
    "    print(f\"\\n  ‚úÖ GATE 2C PASSED\")\n",
    "    print(f\"  Normalization map ready. Extraction function can use it.\")\n",
    "    print(f\"  Next: Full-book extraction with normalization + coreference flagging\")\n",
    "else:\n",
    "    print(f\"\\n  ‚ö†Ô∏è  SOME CHECKS FAILED\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
